#  Agente de Razonamiento RAG Local Qwen 3

Esta Aplicaci贸n RAG demuestra c贸mo construir un potente sistema de Generaci贸n Aumentada por Recuperaci贸n (RAG) utilizando modelos Qwen 3 y Gemma 3 ejecut谩ndose localmente a trav茅s de Ollama. Combina procesamiento de documentos, b煤squeda vectorial y capacidades de b煤squeda web para proporcionar respuestas precisas y conscientes del contexto a las consultas de los usuarios.

## Caracter铆sticas

- ** M煤ltiples Opciones de LLM Locales**:

  - Qwen3 (1.7b, 8b) - ltimos modelos de lenguaje de Alibaba
  - Gemma3 (1b, 4b) - Modelos de lenguaje eficientes de Google con capacidades multimodales
  - DeepSeek (1.5b) - Opci贸n de modelo alternativa
- ** Sistema RAG Completo**:

  - Carga y procesa documentos PDF
  - Extrae contenido de URL web
  - Fragmentaci贸n y embedding inteligentes
  - B煤squeda de similitud con umbral ajustable
- ** Integraci贸n de B煤squeda Web**:

  - Respaldo a b煤squeda web cuando el conocimiento del documento es insuficiente
  - Filtrado de dominio configurable
  - Atribuci贸n de fuentes en las respuestas
- ** Modos de Operaci贸n Flexibles**:

  - Alterna entre RAG e interacci贸n directa con LLM
  - Fuerza la b煤squeda web cuando sea necesario
  - Ajusta los umbrales de similitud para la recuperaci贸n de documentos
- ** Integraci贸n de Base de Datos Vectorial**:

  - Base de datos vectorial Qdrant para b煤squeda eficiente por similitud
  - Almacenamiento persistente de embeddings de documentos

## C贸mo Empezar

### Requisitos Previos

- [Ollama](https://ollama.ai/) instalado localmente
- Python 3.8+
- Cuenta Qdrant (nivel gratuito disponible) para almacenamiento de vectores
- Clave API de Exa (opcional, para capacidad de b煤squeda web)

### Instalaci贸n

1. Clona el repositorio de GitHub

```bash
git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git
cd rag_tutorials/qwen_local_rag
```

2. Instala las dependencias requeridas:

```bash
pip install -r requirements.txt
```

3. Descarga los modelos requeridos usando Ollama:

```bash
ollama pull qwen3:1.7b # O cualquier otro modelo que quieras usar
ollama pull snowflake-arctic-embed # O cualquier otro modelo que quieras usar
```
4. Ejecuta Qdrant localmente a trav茅s de docker
```bash
docker pull qdrant/qdrant

docker run -p 6333:6333 -p 6334:6334 \
    -v "$(pwd)/qdrant_storage:/qdrant/storage:z" \
    qdrant/qdrant
```


4. Obt茅n tus claves API:

   - Clave API de Exa (opcional, para b煤squeda web)
   
5. Ejecuta la aplicaci贸n:

```bash
streamlit run qwen_local_rag_agent.py
```

## C贸mo Funciona

1. **Procesamiento de Documentos**:

   - Los archivos PDF se procesan usando PyPDFLoader
   - El contenido web se extrae usando WebBaseLoader
   - Los documentos se dividen en fragmentos con RecursiveCharacterTextSplitter
2. **Base de Datos Vectorial**:

   - Los fragmentos de documentos se incrustan usando los modelos de embedding de Ollama
   - Los embeddings se almacenan en la base de datos vectorial Qdrant
   - La b煤squeda por similitud recupera documentos relevantes basados en la consulta
3. **Procesamiento de Consultas**:

   - Las consultas de los usuarios se analizan para determinar la mejor fuente de informaci贸n
   - El sistema verifica la relevancia del documento usando el umbral de similitud
   - Recurre a la b煤squeda web si no se encuentran documentos relevantes
4. **Generaci贸n de Respuestas**:

   - El LLM local (Qwen/Gemma) genera respuestas basadas en el contexto recuperado
   - Las fuentes se citan y se muestran al usuario
   - Los resultados de la b煤squeda web se indican claramente cuando se utilizan

## Opciones de Configuraci贸n

- **Selecci贸n de Modelo**: Elige entre diferentes modelos Qwen, Gemma y DeepSeek
- **Modo RAG**: Alterna entre RAG habilitado e interacci贸n directa con LLM
- **Ajuste de B煤squeda**: Ajusta el umbral de similitud para la recuperaci贸n de documentos
- **B煤squeda Web**: Habilita/deshabilita el respaldo de b煤squeda web y configura el filtrado de dominios

## Casos de Uso

- **Preguntas y Respuestas sobre Documentos**: Haz preguntas sobre tus documentos cargados
- **Asistente de Investigaci贸n**: Combina el conocimiento de los documentos con la b煤squeda web
- **Privacidad Local**: Procesa documentos sensibles sin enviar datos a API externas
- **Operaci贸n sin Conexi贸n**: Ejecuta capacidades avanzadas de IA con acceso limitado o nulo a internet

## Requisitos

Consulta `requirements.txt` para la lista completa de dependencias.
