##  Aplicaci贸n LLM con Memoria
Esta aplicaci贸n de Streamlit es un chatbot impulsado por IA que utiliza el modelo GPT-4o de OpenAI con una funci贸n de memoria persistente. Permite a los usuarios tener conversaciones con la IA mientras se mantiene el contexto a trav茅s de m煤ltiples interacciones.

### Caracter铆sticas

- Utiliza el modelo GPT-4o de OpenAI para generar respuestas
- Implementa memoria persistente utilizando Mem0 y el almac茅n de vectores Qdrant
- Permite a los usuarios ver su historial de conversaciones
- Proporciona una interfaz f谩cil de usar con Streamlit


### 驴C贸mo Empezar?

1. Clona el repositorio de GitHub
```bash
git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git
cd awesome-llm-apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory
```

2. Instala las dependencias requeridas:

```bash
pip install -r requirements.txt
```

3. Aseg煤rate de que Qdrant est茅 en ejecuci贸n:
La aplicaci贸n espera que Qdrant est茅 en ejecuci贸n en localhost:6333. Ajusta la configuraci贸n en el c贸digo si tu configuraci贸n es diferente.

```bash
docker pull qdrant/qdrant

docker run -p 6333:6333 -p 6334:6334 \
    -v $(pwd)/qdrant_storage:/qdrant/storage:z \
    qdrant/qdrant
```

4. Ejecuta la Aplicaci贸n Streamlit
```bash
streamlit run llm_app_memory.py
```
