import os
import json
import re
import sys
import io
import contextlib
import warnings
from typing import Optional, List, Any, Tuple
from PIL import Image
import streamlit as st
import pandas as pd
import base64
from io import BytesIO
from together import Together
from e2b_code_interpreter import Sandbox

warnings.filterwarnings("ignore", category=UserWarning, module="pydantic")

pattern = re.compile(r"```python\n(.*?)\n```", re.DOTALL)

def code_interpret(e2b_code_interpreter: Sandbox, code: str) -> Optional[List[Any]]:
    with st.spinner('Ejecutando c贸digo en el sandbox E2B...'):
        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()

        with contextlib.redirect_stdout(stdout_capture), contextlib.redirect_stderr(stderr_capture):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                exec = e2b_code_interpreter.run_code(code)

        if stderr_capture.getvalue():
            print("[Advertencias/Errores del Int茅rprete de C贸digo]", file=sys.stderr)
            print(stderr_capture.getvalue(), file=sys.stderr)

        if stdout_capture.getvalue():
            print("[Salida del Int茅rprete de C贸digo]", file=sys.stdout)
            print(stdout_capture.getvalue(), file=sys.stdout)

        if exec.error:
            print(f"[ERROR del Int茅rprete de C贸digo] {exec.error}", file=sys.stderr)
            return None
        return exec.results

def match_code_blocks(llm_response: str) -> str:
    match = pattern.search(llm_response)
    if match:
        code = match.group(1)
        return code
    return ""

def chat_with_llm(e2b_code_interpreter: Sandbox, user_message: str, dataset_path: str) -> Tuple[Optional[List[Any]], str]:
    # Update system prompt to include dataset path information
    system_prompt = f"""Eres un cient铆fico de datos Python y experto en visualizaci贸n de datos. Se te proporciona un conjunto de datos en la ruta '{dataset_path}' y tambi茅n la consulta del usuario.
Necesitas analizar el conjunto de datos y responder a la consulta del usuario con una respuesta y ejecutar c贸digo Python para resolverlos.
IMPORTANTE: Siempre usa la variable de ruta del conjunto de datos '{dataset_path}' en tu c贸digo al leer el archivo CSV."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]

    with st.spinner('Obteniendo respuesta del modelo LLM de Together AI...'):
        client = Together(api_key=st.session_state.together_api_key)
        response = client.chat.completions.create(
            model=st.session_state.model_name,
            messages=messages,
        )

        response_message = response.choices[0].message
        python_code = match_code_blocks(response_message.content)
        
        if python_code:
            code_interpreter_results = code_interpret(e2b_code_interpreter, python_code)
            return code_interpreter_results, response_message.content
        else:
            st.warning(f"No se pudo encontrar ning煤n c贸digo Python en la respuesta del modelo")
            return None, response_message.content

def upload_dataset(code_interpreter: Sandbox, uploaded_file) -> str:
    dataset_path = f"./{uploaded_file.name}"
    
    try:
        code_interpreter.files.write(dataset_path, uploaded_file)
        return dataset_path
    except Exception as error:
        st.error(f"Error durante la carga del archivo: {error}")
        raise error


def main():
    """Main Streamlit application."""
    st.title(" Agente de Visualizaci贸n de Datos con IA")
    st.write("隆Sube tu conjunto de datos y haz preguntas sobre 茅l!")

    # Initialize session state variables
    if 'together_api_key' not in st.session_state:
        st.session_state.together_api_key = ''
    if 'e2b_api_key' not in st.session_state:
        st.session_state.e2b_api_key = ''
    if 'model_name' not in st.session_state:
        st.session_state.model_name = ''

    with st.sidebar:
        st.header("Claves API y Configuraci贸n del Modelo")
        st.session_state.together_api_key = st.sidebar.text_input("Clave API de Together AI", type="password")
        st.sidebar.info(" Todos obtienen un cr茅dito gratuito de $1 de Together AI - Plataforma en la Nube para Aceleraci贸n de IA")
        st.sidebar.markdown("[Obtener Clave API de Together AI](https://api.together.ai/signin)")
        
        st.session_state.e2b_api_key = st.sidebar.text_input("Ingresar Clave API de E2B", type="password")
        st.sidebar.markdown("[Obtener Clave API de E2B](https://e2b.dev/docs/legacy/getting-started/api-key)")
        
        # Add model selection dropdown
        model_options = {
            "Meta-Llama 3.1 405B": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            "DeepSeek V3": "deepseek-ai/DeepSeek-V3",
            "Qwen 2.5 7B": "Qwen/Qwen2.5-7B-Instruct-Turbo",
            "Meta-Llama 3.3 70B": "meta-llama/Llama-3.3-70B-Instruct-Turbo"
        }
        st.session_state.model_name = st.selectbox(
            "Seleccionar Modelo",
            options=list(model_options.keys()),
            index=0  # Default to first option
        )
        st.session_state.model_name = model_options[st.session_state.model_name]

    uploaded_file = st.file_uploader("Elige un archivo CSV", type="csv")
    
    if uploaded_file is not None:
        # Display dataset with toggle
        df = pd.read_csv(uploaded_file)
        st.write("Conjunto de datos:")
        show_full = st.checkbox("Mostrar conjunto de datos completo")
        if show_full:
            st.dataframe(df)
        else:
            st.write("Vista previa (primeras 5 filas):")
            st.dataframe(df.head())
        # Query input
        query = st.text_area("驴Qu茅 te gustar铆a saber sobre tus datos?",
                            "驴Puedes comparar el costo promedio para dos personas entre diferentes categor铆as?")
        
        if st.button("Analizar"):
            if not st.session_state.together_api_key or not st.session_state.e2b_api_key:
                st.error("Por favor, ingresa ambas claves API en la barra lateral.")
            else:
                with Sandbox(api_key=st.session_state.e2b_api_key) as code_interpreter:
                    # Upload the dataset
                    dataset_path = upload_dataset(code_interpreter, uploaded_file)
                    
                    # Pass dataset_path to chat_with_llm
                    code_results, llm_response = chat_with_llm(code_interpreter, query, dataset_path)
                    
                    # Display LLM's text response
                    st.write("Respuesta de la IA:")
                    st.write(llm_response)
                    
                    # Display results/visualizations
                    if code_results:
                        for result in code_results:
                            if hasattr(result, 'png') and result.png:  # Check if PNG data is available
                                # Decode the base64-encoded PNG data
                                png_data = base64.b64decode(result.png)
                                
                                # Convert PNG data to an image and display it
                                image = Image.open(BytesIO(png_data))
                                st.image(image, caption="Visualizaci贸n Generada", use_container_width=False)
                            elif hasattr(result, 'figure'):  # For matplotlib figures
                                fig = result.figure  # Extract the matplotlib figure
                                st.pyplot(fig)  # Display using st.pyplot
                            elif hasattr(result, 'show'):  # For plotly figures
                                st.plotly_chart(result)
                            elif isinstance(result, (pd.DataFrame, pd.Series)):
                                st.dataframe(result)
                            else:
                                st.write(result)  

if __name__ == "__main__":
    main()