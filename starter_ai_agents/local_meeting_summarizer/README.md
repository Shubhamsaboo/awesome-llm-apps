# ğŸ™ï¸ Local AI Meeting Summarizer

A completely private meeting summarizer that runs 100% locally on your machine. No API keys needed. No data leaves your computer.

## Features

- **Local Transcription** â€” OpenAI Whisper runs on your machine, no API calls
- **Local Summarization** â€” Ollama + Llama 3.1 for structured summaries
- **Action Item Extraction** â€” Automatically identifies tasks, owners, and deadlines
- **Decision Tracking** â€” Captures decisions made during the meeting
- **Timestamped Transcript** â€” Browse the full transcript with timestamps
- **Markdown Export** â€” Download the summary as a markdown file
- **Multiple Audio Formats** â€” MP3, WAV, M4A, MP4, WebM, OGG, FLAC

## How It Works

```
Audio File â†’ Whisper (local transcription) â†’ Ollama (local summarization) â†’ Structured Summary
```

1. Upload a meeting recording
2. Whisper transcribes the audio locally
3. Ollama analyzes the transcript and extracts:
   - Executive summary
   - Key topics discussed
   - Decisions made
   - Action items with owners and deadlines
   - Open questions needing follow-up
   - Overall meeting sentiment

## Getting Started

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com) installed and running
- FFmpeg (`brew install ffmpeg` on macOS)

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Pull an LLM model
ollama pull llama3.1:8b

# Run the app
streamlit run local_meeting_summarizer.py
```

### Choosing Models

**Whisper Models** (transcription):
| Model | Speed | Accuracy | RAM |
|-------|-------|----------|-----|
| tiny | âš¡âš¡âš¡ | â˜…â˜… | ~1 GB |
| base | âš¡âš¡ | â˜…â˜…â˜… | ~1 GB |
| small | âš¡âš¡ | â˜…â˜…â˜…â˜… | ~2 GB |
| medium | âš¡ | â˜…â˜…â˜…â˜…â˜… | ~5 GB |
| large | ğŸ¢ | â˜…â˜…â˜…â˜…â˜… | ~10 GB |

**Ollama Models** (summarization):
- `llama3.1:8b` â€” Fast, good quality (recommended)
- `llama3.1:70b` â€” Higher quality, needs more RAM
- `mistral:7b` â€” Good alternative
- Any model available in Ollama works

## Privacy

Everything runs locally:
- **Whisper** processes audio on your CPU/GPU â€” no OpenAI API calls
- **Ollama** runs the LLM on your machine â€” no cloud inference
- **No data is sent anywhere** â€” your meetings stay private
